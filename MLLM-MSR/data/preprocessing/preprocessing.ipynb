{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import pandas as pd\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../MicroLens-50k_pairs.csv')\n",
    "print(f'shape: {df.shape}')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "min_u_num, min_i_num = 7, 5\n",
    "\n",
    "def get_illegal_ids_by_inter_num(df, field, max_num=None, min_num=None):\n",
    "    if field is None:\n",
    "        return set()\n",
    "    if max_num is None and min_num is None:\n",
    "        return set()\n",
    "\n",
    "    max_num = max_num or np.inf\n",
    "    min_num = min_num or -1\n",
    "\n",
    "    ids = df[field].values\n",
    "    inter_num = Counter(ids)\n",
    "    ids = {id_ for id_ in inter_num if inter_num[id_] < min_num or inter_num[id_] > max_num}\n",
    "    print(f'{len(ids)} illegal_ids_by_inter_num, field={field}')\n",
    "\n",
    "    return ids\n",
    "\n",
    "\n",
    "def filter_by_k_core(df):\n",
    "    while True:\n",
    "        ban_users = get_illegal_ids_by_inter_num(df, field='user', max_num=None, min_num=min_u_num)\n",
    "        ban_items = get_illegal_ids_by_inter_num(df, field='item', max_num=None, min_num=min_i_num)\n",
    "        if len(ban_users) == 0 and len(ban_items) == 0:\n",
    "            return\n",
    "\n",
    "        dropped_inter = pd.Series(False, index=df.index)\n",
    "        if 'user':\n",
    "            dropped_inter |= df['user'].isin(ban_users)\n",
    "        if 'item':\n",
    "            dropped_inter |= df['item'].isin(ban_items)\n",
    "        print(f'{len(dropped_inter)} dropped interactions')\n",
    "        df.drop(df.index[dropped_inter], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_by_k_core(df)\n",
    "print(f'k-core shape: {df.shape}')\n",
    "print(f'shape after k-core: {df.shape}')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['user'].nunique())\n",
    "print(df['item'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df has three columns: 'user', 'item', 'timestamp'\n",
    "\n",
    "# calculate the frequency of each item\n",
    "item_frequency = df.groupby('item').size().reset_index(name='frequency')\n",
    "\n",
    "# sort items by frequency in descending order\n",
    "item_frequency_sorted = item_frequency.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# sort the original dataframe by timestamp\n",
    "df_sorted = df.sort_values('timestamp')\n",
    "\n",
    "# get all unique items and users\n",
    "all_items = set(df_sorted['item'].unique())\n",
    "all_users = df_sorted['user'].unique()\n",
    "\n",
    "# generate negative samples for each user\n",
    "negative_samples_per_user = {}\n",
    "for user in all_users:\n",
    "    user_items = df_sorted[df_sorted['user'] == user]['item'].unique()\n",
    "    available_items = list(all_items - set(user_items))\n",
    "    negative_samples = np.random.choice(available_items, size=min(20, len(available_items)), replace=False)\n",
    "    negative_samples_per_user[user] = negative_samples\n",
    "\n",
    "print(len(negative_samples_per_user.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_6_items_per_user = {}\n",
    "for user in all_users:\n",
    "    # get the items interacted by the user\n",
    "    user_items = df_sorted[df_sorted['user'] == user]['item']\n",
    "    # get the top 6 items based on frequency\n",
    "    top_6_items = user_items.map(item_frequency_sorted.set_index('item')['frequency']).sort_values(ascending=False).index[:6]\n",
    "    # sorted these top 6 items by timestamp\n",
    "    top_6_items_per_user[user] = df_sorted.loc[top_6_items].sort_value('timestamp')['item'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for user in all_users:\n",
    "    top_items_str = ', '.join([str(item) for item in top_6_items_per_user[user]])\n",
    "    negative_samples_str = ', '.join([str(item) for item in negative_samples_per_user[user]])\n",
    "    # format the line as \"user_id\\ttop_items\\tnegative_samples\"\n",
    "    line = f\"{user}\\t{top_items_str}\\t{negative_samples_str}\"\n",
    "    lines.append(line)\n",
    "\n",
    "tsv_file_path = 'user_items_negs.tsv'\n",
    "with open(tsv_file_path, 'w') as file:\n",
    "    file.write('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tsv_file_path = 'user_items_negs.tsv'\n",
    "data = pd.read_csv(tsv_file_path, sep='\\t', header=None, names=['user', 'items', 'negative_samples'])\n",
    "\n",
    "users = data['user'].unique()\n",
    "\n",
    "train_users, test_val_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "val_users, test_users = train_test_split(test_val_users, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = data[data['user'].isin(train_users)]\n",
    "val_data = data[data['user'].isin(val_users)]\n",
    "test_data = data[data['user'].isin(test_users)]\n",
    "\n",
    "print(f\"Training data size: {len(train_data)}\")\n",
    "print(f\"Validation data size: {len(val_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_tsv(df, file_path):\n",
    "    df.to_csv(file_path, sep='\\t', header=False, index=False)\n",
    "    print(f\"File saved to {file_path}\")\n",
    "\n",
    "# save the dataframes to TSV files\n",
    "save_to_tsv(train_data, 'train.tsv')\n",
    "save_to_tsv(val_data, 'val.tsv')\n",
    "save_to_tsv(test_data, 'test.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
